骆驼(Luotuo): Chinese-alpaca-lora
https://github.com/LC1332/Chinese-alpaca-lora

Stanford Alpaca: An Instruction-following LLaMA Model
https://github.com/tatsu-lab/stanford_alpaca

LLaMA
https://github.com/facebookresearch/llama
模型文件下载
https://ipfs.io/ipfs/Qmb9y5GCkTG7ZzbBWMu2BXwMkzyCKcUjtEKPpgdZ7GEFKm/

有关的一些新微调方式
https://huggingface.co/blog/stackllama
https://github.com/lm-sys/FastChat/#fine-tuning

清华
https://github.com/THUDM/ChatGLM-6B
https://models.aminer.cn/glm-130b/
https://github.com/THUDM/GLM-130B
glm-10b
https://github.com/THUDM/GLM#generation
ChatGLM创意
https://github.com/ypwhs/CreativeChatGLM
https://lslfd0slxc.feishu.cn/docx/JAgsd5WVgoZ1bKxYzq0c8gh5neh

清华模型微调
https://github.com/mymusise/ChatGLM-Tuning
https://github.com/liucongg/ChatGLM-Finetuning


BELLE(基于BLOOM和LLAMA针对中文做了优化)
https://github.com/LianjiaTech/BELLE
https://huggingface.co/BelleGroup/BELLE-7B-2M


中文LLaMA模型和经过指令精调的Alpaca大模型
https://github.com/ymcui/Chinese-LLaMA-Alpaca

Chinese-alpaca-lora
https://github.com/fecet/alpaca-lora-Chinese
https://github.com/tloen/alpaca-lora

开源指令数据集
https://github.com/yanqiangmiffy/InstructGLM


https://huggingface.co/IDEA-CCNL/Randeng-TransformerXL-5B-Deduction-Chinese
https://huggingface.co/IDEA-CCNL/Randeng-TransformerXL-5B-Abduction-Chinese

提示的写法
https://jerryzou.com/posts/how-to-write-a-prompt-for-chatgpt/

HuggingGPT
https://github.com/microsoft/JARVIS

GPT4ALL
https://github.com/nomic-ai/gpt4all

AutoGPT
https://github.com/Significant-Gravitas/Auto-GPT

MOSS
https://github.com/OpenLMLab/MOSS

RLHF
https://github.com/sunzeyeah/RLHF
